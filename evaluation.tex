\chapter{Evaluation}\label{ch:Evaluation}

In order to evaluate the effectiveness of the newly developed interpolating intersection logic,
three test cases will be used and compared to the snapshot method.
\newline
The first test case is simple: A receiver moves towards an emitter at 1/9th the speed of sound.
It starts 342.2 meters away from the emitter.
The emitter sends out a sine wave at 440Hz for 1 second.
No other objects are in the scene.
\newline
This is essentially the example described in \ref{im:SnapshotExplain}
and is used to demonstrate the basic differences between interpolated and snapshot methods.
\newline
\begin{figure}[t!]
    \includesvg[width=\linewidth]{images/test_rooms.svg}
    \caption{The second (left) and third (right) test scene, with the emitter, receiver and rotation axis all denoted by the black dot.}\label{fig:TestScenes}
\end{figure}
The second test case takes place inside a rotating rectangular room as seen on the left side of \autoref{fig:TestScenes}.
Said room is 4 meters in width and length and 3 meters tall.
The receiver is exactly in the middle of the room,
with the emitter being 1.2 meters above it.
The room rotates around the Z-axis, completing a full rotation once per second.
\newline
This is used to test whether the differences between interpolated and snapshot methods
lead to a notable difference in a slightly more practical scenario.
\newline
The third test case takes place inside a rotating, 2 meters tall L-shaped room,
as denoted on the right side of \autoref{fig:TestScenes},
with the receiver being at the origin at 1 meter height and the emitter being 0.5 meters above it.
The room again rotates around the Z-axis, but takes three seconds for a full rotation.
\newline
This case is used to demonstrate the shortcomings of the interpolating intersection logic
and the need for further research for realistic simulations.

\section{Testing Conditions}

Tests were performed on a stock AMD Ryzen 3600xt CPU with 16GB of 3200MHz DDR4 RAM.
All 12 logical cores are used for parallel processing
and no other programs other than a shell for the program to run in (and Windows 10 background processes) were running to avoid needless interference.
\newline
The proof-of-concept used for testing was written in Rust, using the \verb|nalgebra| crate for algebra functions,
\verb|roots| for polynomial solving and \verb|rayon| for parallelisation.
For simplicity's sake, only an energetic response was calculated, not an impulse response.
This leads to less accurate auralization as phase is disregarded,
but is sufficient to show basic differences between the snapshot and interpolated method.
\newline
The first test case with the approaching receiver is run using one ray per sample
as it only attempts to simulate sound travelling from emitter to receiver
without considering bounces from a room around it.
The ray is always directed at the receiver.
\newline
The other two test cases are run using 10 million rays per sample,
which is enough to get an approximate \(T_{60}\) sufficient to draw conclusions about the scenes
while requiring a reasonable amount of compute time.
To account for variance introduced by randomness, 3 runs are done per simulation method and scene.
\newline
For the two rotating scenes, only one energetic response is calculated and applied to all samples.
This is because the starting condition of a rotating room is always the same:
As both rooms rotate around the emitter's and the receiver's position
and the emitter emits rays randomly in all directions,
the relative position of the room to the receiver and emitter is always the same,
making for the same energetic response at all times.
\newline
Simulations would become much more expensive for scenes where this condition doesn't apply,
as that would mean calculating individual impulse responses for each sample.
For a 1 second sample at 44100 KHz and a roughly 20 minute IR calculation time
(rounded down from the snapshot method test results below),
this would take \(44100 \cdot 20 m = 882000 m = 14700 h = 612.5 d\).
Running simulations for such scenes would require optimisations, much stronger hardware
and/or conceits on ray count to be able to run in a reasonable time.
\newline
All walls in scenes that contain any have a material roughly resembling smooth concrete walls' behaviour for high frequencies.
The absorption coefficient \(\alpha_{rand}\), based on data by acoustic.ua (\url{https://www.acoustic.ua/st/web_absorption_data_eng.pdf}),
is 0.98, meaning that a ray retains 98\% of its energy after bouncing.
Data for diffusion coefficients is not publicly available, so by guesswork, a value of 0.1 was used,
meaning that 90\% of the energy is specularly reflected, while 10\% is diffusely reflected.
In practice, this means that rays have a 10\% chance to bounce in a random direction rather than reflecting off the surface normally.
\newline
Rays get discarded once their energy has decreased by six orders of magnitude,
which translates to their energy being at least 60 decibels quieter than the original sound.
This means that \(T_{60}\) equals the length of the impulse response.
The clarity \(C_{50}\) is calculated from the impulse response using the logic from \ref{eq:C50}
in a separate python script.
The initial silence before direct sound arrives at the receiver is ignored for this calculation.
\newline
Note that all \(C_{50}\) values for the test scenes are very low compared to real-world rooms.
This is because all the test scenes are large, empty rooms,
the walls of which have a rather low absorption coefficient,
leading to long late reverberation.

\section{Approaching Receiver Scene}

In theory, two effects should be observable here.
\newline
Firstly, the ray would take 1 second to arrive at the emitter's position.
As the emitter is travelling towards the ray and covering a tenth of the distance in the time the ray travels the remainder,
the sound should already start at 0.9 seconds.
\newline
Secondly, due to the emitter's fast movement,
the doppler effect would lead to a shift in frequency.
\newline
Using the well-known doppler effect formula with a propagation speed \(c = 342.2 m/s\), an emitter speed \(v_s = 0 m/s\),
a receiver speed \(v_r = 342.2/9 m/s = 38.0\bar{2} m/s\) and a base frequency \(f_0 = 440 Hz\),
the resulting frequency can be calculated as
\begin{equation}\label{eq:Doppler}
    f = \frac{c + v_r}{c + v_s} f_0 = \frac{342.2 m/s + 38.0\bar{2} m/s}{342.2 m/s} \cdot 440Hz = 488.\bar{8} Hz
\end{equation}

\begin{figure}[t!]
    \begin{center}
        \includegraphics{images/approach-waves.png}
    \end{center}
    \caption{The output for test scene 1 for the interpolated (top) and snapshot (bottom) method, visualized using Audacity.}\label{fig:ApproachWaves}
\end{figure}

As expected and clearly visible in \autoref{fig:ApproachWaves}, the first effect can be observed in the interpolated version of the simulation,
but not in the simulation using the snapshot method.
This is because for the snapshot method,
only the initial position of the receiver is relevant to the distance a ray needs to travel until it arrives at said receiver.
Thus, the ray has to travel the full 343.2 meters for the initial impulse response, as shown in~\autoref{im:SnapshotExplain}.
The interpolated version instead takes this effect into account correctly.
\newline
One notable detail is that the interpolated method also simulates the doppler effect more accurately.
The resulting signal from the interpolated method exactly matches the \(488.\bar{8} Hz\) calculated in~\eqref{eq:Doppler},
while the snapshot method instead arrives at a frequency of approximately \(495 Hz\).
\newline
This difference in frequency can be explained by a difference in the actual travelling distance:
In the snapshot method, the receiver first receives signal after \(1s\),
with the final bit of signal arriving at \(1.9s\).
For the interpolated simulation, those numbers are \(0.9s\) and \(1.8s\) respectively.
The signal is thus heard for \(0.9s\) for both receivers.
\newline
Where the receivers' behaviour differs is in the distance they travel in the meantime:
The interpolated method's receiver first starts getting a signal after having travelled for \(34.22\) meters,
with it receiving the last signal after a \(68.44m\) travel distance,
meaning it moved for a total of \(34.22m\) over the course of receiving this signal.
Since the snapshot method doesn't take receiver movement into account,
the first signal is received after \(0m\) of travel distance,
with the final part arriving after \(38.0\bar{2}m\) of travel distance.
\newline
The difference in travel speed thus explains the difference in frequency shift,
seeing as the doppler effect directly relates to velocity.
The snapshot method's result is physically impossible:
If the frequency is shifted higher up,
the pitched-up signal would last shorter than it does with the real pitch shift.
\newline
This goes to show that the interpolated method does help to eliminate this class of error from simulation of moving scenes.
\newline
A noteworthy implementation detail becomes apparent from the waveform resulting from the simulation:
As the input signal is a single sine wave and the doppler effect would only raise its frequency,
the resulting wave should still be a pure sine wave.
In contrast, the actual result for both simulation types features aliasing effects.
\newline
This is because the simulation is run as the same sample rate as the input signal.
For each input sample, one energetic response is calculated.
As the doppler effect speeds up the incoming signal,
but the sped up signal is not upsampled accordingly,
the same effect as if the signal was downsampled and stayed at the same frequency is created.
\newline
To alleviate this, one would need to either run the signal through a low-pass filter ahead of time
or have both the input signal and simulation at a higher sample rate,
then filter and downsample to the target sample rate afterwards.
\newline
The former works, but might damage a signal more complex than a sine wave
and requires knowledge of the scene ahead of time.
For a more complex scene where the downsampling effect cannot be easily calculated prematurely,
this approach becomes unusable.
\newline
The latter leads to increased computation cost as more energetic responses need to be calculated for more signals,
but works with any arbitrary scene.

\section{Rotating Cube Scene}

\begin{table}[t!]
    \centering
    \begin{tabular}{| c | c | c | c | c | c | c |}
        \hline
        Run        & Snapshot 1 & Snapshot 2 & Snapshot 3 & Interp. 1 & Interp. 2 & Interp. 3 \\
        \hline
        Time       & 0:22:33    & 0:22:42    & 0:22:32    & 4:29:42   & 4:11:32   & 4:13:18   \\
        \hline
        \(T_{60}\) & 5.18s      & 5.18s      & 5.20s      & 5.27s     & 5.20s     & 5.18s     \\
        \hline
        \(C_{50}\) & -7.94dB    & -7.93dB    & -7.95dB    & -8.29dB   & -8.29dB   & -8.27dB   \\
        \hline
    \end{tabular}
    \caption{Rotating Cube Test Results}\label{tbl:CubeSceneTable}
\end{table}
There is very little difference in the reverberation time \(T_{60}\) between the snapshot and interpolated version of this scene.
This was to be expected:
The distance a ray has to travel to go from one end of the room to the other hardly changes between the rotating and static version of the room.
Since the angle at which a ray bounces becomes insignificant as reflections become diffuse over time,
there is no significant difference between the snapshot (static) and interpolated (non-static) version of the cube scene.
\newline
\begin{figure}[t!]
    \begin{center}
        \input{images/partial_cube_compare.pgf}
    \end{center}
    \caption{The first 5000 samples of the energetic response for the rotating cube scene and snapshot/interpolated simulation, respectively}\label{fig:CubeSceneIR}
\end{figure}
\begin{figure}[t!]
    \begin{center}
        \includesvg{images/cube_reflections.svg}
    \end{center}
    \caption{A ray taking the same bouncing distance for the snapshot (left) and interpolated (right) version of the square room scene.}\label{fig:CubeRotation}
\end{figure}
\autoref{fig:CubeSceneIR} shows that the early reflections are practically identical between the snapshot and interpolated method.
This is due to the emitter and receiver being on the scene's rotation axis,
which in turn means that the scene is always the same relative to both emitter and receiver, just rotated,
as shown in \autoref{fig:CubeRotation}.
\newline
Thus, the bouncing behaviour for a ray bouncing off a wall once before hitting the receiver
in the snapshot simulation happens the same way in the interpolated simulation,
requiring only a different initial direction to account for the room's rotation.
Rays are equally distributed in all directions, hence the result being equal.
\newline
In a complete simulation including physical forces caused by the room rotation,
the early reflections would differ from those showing here.
This will be discussed further in \autoref{sec:LRoom}.
\newline
The notable difference between the two energetic responses in \autoref{fig:CubeSceneIR}
lies in the energetic response of the interpolated version featuring a second set of early reflections,
approximately around the 3000 sample mark (so after roughly 0.07 seconds).
These later early reflections do not show in the snapshot method version.
In auralization, these reflections become noticeable in the form of a fast delay effect on the input signal.
\newline
\begin{figure}[t!]
    \begin{center}
        \includesvg{images/cube_second_er.svg}
    \end{center}
    \caption{A ray that would take lots of bounces to return to the emitter in a static scene (left) moves in a very different angle in a rotating scene (right), potentially causing a second set of early reflections.}\label{fig:CubeSecondER}
\end{figure}
This effect could come from rays whose initial direction points towards one of the room's side walls,
with the direction being almost orthogonal to said wall, as seen on the left side of \autoref{fig:CubeSecondER}.
In the snapshot version of the simulation, assuming they don't get reflected diffusely,
these rays bounce back and forth between opposite walls while hardly moving horizontally,
meaning it takes long for them to arrive at the receiver again.
These rays thus only end up in the late reverberation part of the energetic response.
\newline
As the angle of the walls changes as they rotate in the interpolated version,
the angle these rays bounce at changes too, visualized in \autoref{fig:CubeSecondER}.
This presumably leads to them coming back to the receiver earlier, creating the later early reflections.
\newline
This second set of early reflections also explains the difference in sound clarity \(C_{50}\) seen in \autoref{tbl:CubeSceneTable}:
Since these later reflections take place after the 50 millisecond mark,
they worsen intelligibility, leading to a decreased clarity.

\section{Rotating L-Shaped Room Scene}\label{sec:LRoom}

\begin{table}[t!]
    \centering
    \begin{tabular}{| c | c | c | c | c | c | c |}
        \hline
        Run        & Snapshot 1 & Snapshot 2 & Snapshot 3 & Interp. 1 & Interp. 2 & Interp. 3 \\
        \hline
        Time       & 0:23:50    & 0:23:45    & 0:23:49    & 6:44:09   & 6:45:59   & 6:45:33   \\
        \hline
        \(T_{60}\) & 5.00s      & 5.18s      & 5.03s      & 5.21s     & 5.11s     & 4.92s     \\
        \hline
        \(C_{50}\) & -2.90dB    & -2.91dB    & -2.90dB    & -3.02dB   & -3.00dB   & -3.03dB   \\
        \hline
    \end{tabular}
    \caption{Rotating L-Shaped Room Test Results}\label{tbl:LSceneTable}
\end{table}

\begin{figure}[t!]
    \begin{center}
        \input{images/partial_l_compare.pgf}
    \end{center}
    \caption{The first 2000 samples of the energetic response for the rotating L-shaped room scene and snapshot/interpolated simulation, respectively}\label{fig:LSceneIR}
\end{figure}

Note that this scene shows a large limitation of the interpolated simulation as it stands:
\begin{figure}[t!]
    \begin{center}
        \includesvg[width=\linewidth]{images/hit_ray_from_back.svg}
    \end{center}
    \caption{A ray (left arrow) bouncing off a rotating wall and then getting hit by that wall from behind.}\label{fig:RayFromBack}
\end{figure}
As the back surface of the room is rotating in a circle,
it is possible for it to hit a ray while that ray is moving away from it,
visualized in \autoref{fig:RayFromBack}.
This would not happen in the real world as pressure gradients would guide the sound wave away from the wall.
\newline
The behaviour for sound waves getting hit by a wall from behind is thus not defined by physics.
For the sake of this simulation, the rays are discarded as they can't bounce off the wall.
This case can be made less likely by having the room rotate at a slower speed:
The lower the rotation speed, the flatter the angle rays have to bounce off the wall at to be able to then get hit by it from behind.
That solution, however, is antithetical to the goal of this research, which is to simulate rapidly rotating rooms.
\newline
To generalise the problem, with the current state of this research,
any scene that involves surfaces moving in a direction roughly orthogonal to themselves breaks the simulation for the reason described above.
Since this condition will apply to most scenes more complex than a single room,
the logic as it stands cannot be used for accurate auralization of moving scenes.
The steps needed to resolve these issues will be outlined in \autoref{ch:Outlook}.
\newline
As the likelihood for a ray to get affected by this problem rises the more it bounces around the scene,
metrics based on late reverberations such as \(T_{60}\) and \(C_{50}\) lose accuracy,
as seen in the \(T_{60}\) varying more between simulation runs than it does for the other simulations.
This renders conclusions drawn from them less useful,
but the data gathered in the test runs is still included in \autoref{tbl:LSceneTable} for completeness' sake.
\newline
The fact that interpolating intersection checks alone do not suffice for an accurate simulation also shows in the energetic responses:
As seen in \autoref{fig:LSceneIR}, the early reflections are almost exactly the same between the snapshot and interpolated simulation,
with only minor differences from slightly different random distribution.
This is the same effect as observed in \autoref{fig:CubeSceneIR} for the square room:
As the room stays the same relative to the emitter and receiver with only the rotation changing
and because the rays are distributed equally in all directions,
rays bouncing off a wall once before hitting the receiver take the same time between the snapshot and interpolated method.
Any difference in acoustics caused by the rotation lies in physical effects equally ignored in both methods.

\section{Performance}

As expected and discussed in \autoref{sec:IntersectionCost},
the performance cost skyrockets for the interpolated method in comparison to the snapshot method.
The factor by which it increases notably changes between the square and L-shaped room scenes:
In the square room scene, the computation time increases by a factor of approximately 12,
whereas that factor becomes approximately 17.5 for the L-shaped room.
\newline
This increase may be caused by more chunks containing more primitives.
Where the corners of the square room contain at most 6 primitives (2 triangles for each attached side),
the inner corner of the L-shaped room's angle may contain up to 8 primitives
as both the side walls and both squares making up the ceiling meet at those corners,
each being made up of 2 triangles.
This intensifies due to the problem mentioned at the end of \autoref{sec:TraversingChunks}
as this higher number of intersection checks is also run multiple times.
\newline
The only test case in which the performance barely differs is the first test scene,
where both the snapshot and interpolated calculation took 3 seconds.
This is presumably because each energetic response is calculated using only a single ray
which only needs to check for intersections with a single object,
making for a comparably low difference between the interpolating and static intersection checks.
\newline
In turn, the implementation of the snapshot method has the additional overhead of re-calculating the scene's chunks for each snapshot scene,
whereas the interpolated method only needs to run the chunk calculation once in the beginning.
This overhead presumably offsets the already little additional cost from the interpolating check.
\newline
This becomes insignificant to a general performance analysis because in practice,
the majority of scenes will use many rays rather than one and be complicated rather than empty.
